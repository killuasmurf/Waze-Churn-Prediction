{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **Waze User Churn Prediction**\n",
    "**Predict how many users will churn soon using Waze dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8Vm3QEfGELS"
   },
   "source": [
    "### **Task 1. Imports and data loading + cleaning**\n",
    "\n",
    "Import packages and libraries needed to build and evaluate random forest and XGBoost classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fKhnX2Puf4Bt"
   },
   "outputs": [],
   "source": [
    "# Import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import packages for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This lets us see all of the columns, preventing Juptyer from redacting them.\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Import packages for data modeling\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# This is the function that helps plot feature importance\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5weTXGKqa_iG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>retained</td>\n",
       "      <td>283</td>\n",
       "      <td>226</td>\n",
       "      <td>296.748273</td>\n",
       "      <td>2276</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2628.845068</td>\n",
       "      <td>1985.775061</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>retained</td>\n",
       "      <td>133</td>\n",
       "      <td>107</td>\n",
       "      <td>326.896596</td>\n",
       "      <td>1225</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>13715.920550</td>\n",
       "      <td>3160.472914</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>retained</td>\n",
       "      <td>114</td>\n",
       "      <td>95</td>\n",
       "      <td>135.522926</td>\n",
       "      <td>2651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3059.148818</td>\n",
       "      <td>1610.735904</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>retained</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>67.589221</td>\n",
       "      <td>15</td>\n",
       "      <td>322</td>\n",
       "      <td>7</td>\n",
       "      <td>913.591123</td>\n",
       "      <td>587.196542</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>retained</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>168.247020</td>\n",
       "      <td>1562</td>\n",
       "      <td>166</td>\n",
       "      <td>5</td>\n",
       "      <td>3950.202008</td>\n",
       "      <td>1219.555924</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     label  sessions  drives  total_sessions  n_days_after_onboarding  \\\n",
       "0   0  retained       283     226      296.748273                     2276   \n",
       "1   1  retained       133     107      326.896596                     1225   \n",
       "2   2  retained       114      95      135.522926                     2651   \n",
       "3   3  retained        49      40       67.589221                       15   \n",
       "4   4  retained        84      68      168.247020                     1562   \n",
       "\n",
       "   total_navigations_fav1  total_navigations_fav2  driven_km_drives  \\\n",
       "0                     208                       0       2628.845068   \n",
       "1                      19                      64      13715.920550   \n",
       "2                       0                       0       3059.148818   \n",
       "3                     322                       7        913.591123   \n",
       "4                     166                       5       3950.202008   \n",
       "\n",
       "   duration_minutes_drives  activity_days  driving_days   device  \n",
       "0              1985.775061             28            19  Android  \n",
       "1              3160.472914             13            11   iPhone  \n",
       "2              1610.735904             14             8  Android  \n",
       "3               587.196542              7             3   iPhone  \n",
       "4              1219.555924             27            18  Android  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset & create download link for CSV file\n",
    "df0 = pd.read_csv('waze_dataset.csv')\n",
    "\n",
    "# from IPython.display import HTML\n",
    "# import base64  \n",
    "# import pandas as pd  \n",
    "\n",
    "# def create_download_link( df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "#     csv = df.to_csv(index =False)\n",
    "#     b64 = base64.b64encode(csv.encode())\n",
    "#     payload = b64.decode()\n",
    "#     html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "#     html = html.format(payload=payload,title=title,filename=filename)\n",
    "#     return HTML(html)\n",
    "\n",
    "# create_download_link(df0)\n",
    "\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mBOSW8IDbO_d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       14999 non-null  int64  \n",
      " 1   label                    14299 non-null  object \n",
      " 2   sessions                 14999 non-null  int64  \n",
      " 3   drives                   14999 non-null  int64  \n",
      " 4   total_sessions           14999 non-null  float64\n",
      " 5   n_days_after_onboarding  14999 non-null  int64  \n",
      " 6   total_navigations_fav1   14999 non-null  int64  \n",
      " 7   total_navigations_fav2   14999 non-null  int64  \n",
      " 8   driven_km_drives         14999 non-null  float64\n",
      " 9   duration_minutes_drives  14999 non-null  float64\n",
      " 10  activity_days            14999 non-null  int64  \n",
      " 11  driving_days             14999 non-null  int64  \n",
      " 12  device                   14999 non-null  object \n",
      "dtypes: float64(3), int64(8), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Copy the df0 dataframe to preserve the original data\n",
    "df = df0.copy()\n",
    "\n",
    "# Call `info()` on the new dataframe so the existing columns can be easily referenced.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows where label is missing, and rows where sessions > total_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14281 entries, 0 to 14280\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       14281 non-null  int64  \n",
      " 1   label                    14281 non-null  object \n",
      " 2   sessions                 14281 non-null  int64  \n",
      " 3   drives                   14281 non-null  int64  \n",
      " 4   total_sessions           14281 non-null  float64\n",
      " 5   n_days_after_onboarding  14281 non-null  int64  \n",
      " 6   total_navigations_fav1   14281 non-null  int64  \n",
      " 7   total_navigations_fav2   14281 non-null  int64  \n",
      " 8   driven_km_drives         14281 non-null  float64\n",
      " 9   duration_minutes_drives  14281 non-null  float64\n",
      " 10  activity_days            14281 non-null  int64  \n",
      " 11  driving_days             14281 non-null  int64  \n",
      " 12  device                   14281 non-null  object \n",
      "dtypes: float64(3), int64(8), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# drop rows with missing values and assign it back to df\n",
    "df = df.dropna(axis=0).reset_index(drop=True)\n",
    "\n",
    "#drop rows where sessions > total_sessions\n",
    "df = df[df['sessions'] <= df['total_sessions']].reset_index(drop=True)\n",
    "\n",
    "'''\n",
    "This creates a boolean mask — a list of True or False for each row.\n",
    "It keeps only the rows where the number of sessions in the last month is less than the total sessions.\n",
    "'''\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2. Feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPtJEHjcuepR"
   },
   "source": [
    "#### **`km_per_driving_day`**\n",
    "\n",
    "1. Create a feature representing the mean number of kilometers driven on each driving day in the last month for each user. Add this feature as a column to `df`.\n",
    "\n",
    "2. Get descriptive statistics for this new feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vAB6cv6xfvZn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.428100e+04\n",
       "mean              inf\n",
       "std               NaN\n",
       "min      7.282840e+00\n",
       "25%      1.675704e+02\n",
       "50%      3.241371e+02\n",
       "75%      7.606933e+02\n",
       "max               inf\n",
       "Name: km_per_driving_day, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create `km_per_driving_day` feature\n",
    "df['km_per_driving_day'] = df['driven_km_drives'] / df['driving_days']\n",
    "\n",
    "# 2. Get descriptive stats\n",
    "df['km_per_driving_day'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSqM4oiyuuzw"
   },
   "source": [
    "Notice that some values are infinite. This is the result of there being values of zero in the `driving_days` column.\n",
    "1. Convert these values from infinity to zero using `np.inf` to refer to a value of infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vv3owriWuuDQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14281.000000\n",
       "mean       582.042741\n",
       "std       1038.669454\n",
       "min          0.000000\n",
       "25%        136.204820\n",
       "50%        273.297082\n",
       "75%        558.097377\n",
       "max      15420.234110\n",
       "Name: km_per_driving_day, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Convert infinite values to zero and check the descriptive stats again\n",
    "df.loc[df['km_per_driving_day'] == np.inf, 'km_per_driving_day'] = 0\n",
    "# This replaces any values in the column km_per_driving_day that are infinity (np.inf) with 0.\n",
    "df['km_per_driving_day'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZfNE37b-LlJ"
   },
   "source": [
    "#### **`percent_sessions_in_last_month`**\n",
    "\n",
    "1. Create a new column `percent_sessions_in_last_month` that represents the percentage of each user's total sessions that were logged in their last month of use.\n",
    "\n",
    "2. Get descriptive statistics for this new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4mRefXCF-K_c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14281.000000\n",
       "mean         0.449099\n",
       "std          0.286258\n",
       "min          0.000000\n",
       "25%          0.196551\n",
       "50%          0.423209\n",
       "75%          0.686272\n",
       "max          0.999774\n",
       "Name: percent_sessions_in_last_month, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create `percent_sessions_in_last_month` feature\n",
    "df['percent_sessions_in_last_month'] = df['sessions'] / df['total_sessions']\n",
    "\n",
    "df['percent_sessions_in_last_month'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3bWzofHVIuC"
   },
   "source": [
    "#### **`total_sessions_per_day`**\n",
    "\n",
    "Now, create a new column that represents the mean number of sessions per day _since onboarding_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bWXPMPHSVJQd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14281.000000\n",
       "mean         0.338473\n",
       "std          1.320574\n",
       "min          0.000383\n",
       "25%          0.050972\n",
       "50%          0.100534\n",
       "75%          0.215447\n",
       "max         39.763874\n",
       "Name: total_sessions_per_day, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create `total_sessions_per_day` feature\n",
    "df['total_sessions_per_day'] = df['total_sessions'] / df['n_days_after_onboarding']\n",
    "\n",
    "df['total_sessions_per_day'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d6N9jf8ViW-"
   },
   "source": [
    "#### **`km_per_drive`**\n",
    "\n",
    "Rename drives to `drives_last_month`, then create a column representing the mean number of kilometers per drive made in the last month for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "v5R5-MteVlMB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.428100e+04\n",
       "mean              inf\n",
       "std               NaN\n",
       "min      1.008775e+00\n",
       "25%      3.325404e+01\n",
       "50%      7.489207e+01\n",
       "75%      1.853200e+02\n",
       "max               inf\n",
       "Name: km_per_drive, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create `km_per_drive` feature\n",
    "df.rename(columns = {'drives' : 'drives_last_month'}, inplace = True)\n",
    "df['km_per_drive'] = df['driven_km_drives'] / df['drives_last_month']\n",
    "\n",
    "df['km_per_drive'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txY8qR1LVlq1"
   },
   "source": [
    "This feature has infinite values too. Convert the infinite values to zero, then confirm that it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PZrHMuPuVmIt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14281.000000\n",
       "mean       232.045829\n",
       "std        616.100855\n",
       "min          0.000000\n",
       "25%         32.488158\n",
       "50%         72.917447\n",
       "75%        179.257277\n",
       "max      15777.426560\n",
       "Name: km_per_drive, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Convert infinite values to zero\n",
    "df.loc[df['km_per_drive'] == np.inf, 'km_per_drive'] = 0\n",
    "\n",
    "# 2. Confirm that it worked\n",
    "df['km_per_drive'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5Sxs6agVunA"
   },
   "source": [
    "#### **`percent_of_sessions_to_favorite`**\n",
    "\n",
    "Finally, create a new column that represents the percentage of total sessions that were used to navigate to one of the users' favorite places. Then, print descriptive statistics for the new column.\n",
    "\n",
    "This is a proxy representation for the percent of overall drives that are to a favorite place. Since total drives since onboarding are not contained in this dataset, total sessions must serve as a reasonable approximation.\n",
    "\n",
    "People whose drives to non-favorite places make up a higher percentage of their total drives might be less likely to churn, since they're making more drives to less familiar places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vh22o46AVxd_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14270.000000\n",
       "mean         7.884546\n",
       "std         27.345433\n",
       "min          0.000000\n",
       "25%          0.489988\n",
       "50%          1.760572\n",
       "75%          5.300589\n",
       "max        799.000000\n",
       "Name: percent_of_sessions_to_favorite, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create `percent_of_sessions_to_favorite` feature\n",
    "df['percent_of_sessions_to_favorite'] = (df['total_navigations_fav1'] + df['total_navigations_fav2']) / df['sessions']\n",
    "\n",
    "df.loc[df['percent_of_sessions_to_favorite'] == np.inf, 'percent_of_sessions_to_favorite'] = 0\n",
    "# Get descriptive stats\n",
    "df['percent_of_sessions_to_favorite'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the final DataFrame after all feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives_last_month</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>device</th>\n",
       "      <th>km_per_driving_day</th>\n",
       "      <th>percent_sessions_in_last_month</th>\n",
       "      <th>total_sessions_per_day</th>\n",
       "      <th>km_per_drive</th>\n",
       "      <th>percent_of_sessions_to_favorite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>retained</td>\n",
       "      <td>283</td>\n",
       "      <td>226</td>\n",
       "      <td>296.748273</td>\n",
       "      <td>2276</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2628.845068</td>\n",
       "      <td>1985.775061</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>Android</td>\n",
       "      <td>138.360267</td>\n",
       "      <td>0.953670</td>\n",
       "      <td>0.130381</td>\n",
       "      <td>11.632058</td>\n",
       "      <td>0.734982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>retained</td>\n",
       "      <td>133</td>\n",
       "      <td>107</td>\n",
       "      <td>326.896596</td>\n",
       "      <td>1225</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>13715.920550</td>\n",
       "      <td>3160.472914</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1246.901868</td>\n",
       "      <td>0.406856</td>\n",
       "      <td>0.266854</td>\n",
       "      <td>128.186173</td>\n",
       "      <td>0.624060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>retained</td>\n",
       "      <td>114</td>\n",
       "      <td>95</td>\n",
       "      <td>135.522926</td>\n",
       "      <td>2651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3059.148818</td>\n",
       "      <td>1610.735904</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>Android</td>\n",
       "      <td>382.393602</td>\n",
       "      <td>0.841186</td>\n",
       "      <td>0.051121</td>\n",
       "      <td>32.201567</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>retained</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>67.589221</td>\n",
       "      <td>15</td>\n",
       "      <td>322</td>\n",
       "      <td>7</td>\n",
       "      <td>913.591123</td>\n",
       "      <td>587.196542</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>304.530374</td>\n",
       "      <td>0.724968</td>\n",
       "      <td>4.505948</td>\n",
       "      <td>22.839778</td>\n",
       "      <td>6.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>retained</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>168.247020</td>\n",
       "      <td>1562</td>\n",
       "      <td>166</td>\n",
       "      <td>5</td>\n",
       "      <td>3950.202008</td>\n",
       "      <td>1219.555924</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>Android</td>\n",
       "      <td>219.455667</td>\n",
       "      <td>0.499266</td>\n",
       "      <td>0.107713</td>\n",
       "      <td>58.091206</td>\n",
       "      <td>2.035714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     label  sessions  drives_last_month  total_sessions  \\\n",
       "0   0  retained       283                226      296.748273   \n",
       "1   1  retained       133                107      326.896596   \n",
       "2   2  retained       114                 95      135.522926   \n",
       "3   3  retained        49                 40       67.589221   \n",
       "4   4  retained        84                 68      168.247020   \n",
       "\n",
       "   n_days_after_onboarding  total_navigations_fav1  total_navigations_fav2  \\\n",
       "0                     2276                     208                       0   \n",
       "1                     1225                      19                      64   \n",
       "2                     2651                       0                       0   \n",
       "3                       15                     322                       7   \n",
       "4                     1562                     166                       5   \n",
       "\n",
       "   driven_km_drives  duration_minutes_drives  activity_days  driving_days  \\\n",
       "0       2628.845068              1985.775061             28            19   \n",
       "1      13715.920550              3160.472914             13            11   \n",
       "2       3059.148818              1610.735904             14             8   \n",
       "3        913.591123               587.196542              7             3   \n",
       "4       3950.202008              1219.555924             27            18   \n",
       "\n",
       "    device  km_per_driving_day  percent_sessions_in_last_month  \\\n",
       "0  Android          138.360267                        0.953670   \n",
       "1   iPhone         1246.901868                        0.406856   \n",
       "2  Android          382.393602                        0.841186   \n",
       "3   iPhone          304.530374                        0.724968   \n",
       "4  Android          219.455667                        0.499266   \n",
       "\n",
       "   total_sessions_per_day  km_per_drive  percent_of_sessions_to_favorite  \n",
       "0                0.130381     11.632058                         0.734982  \n",
       "1                0.266854    128.186173                         0.624060  \n",
       "2                0.051121     32.201567                         0.000000  \n",
       "3                4.505948     22.839778                         6.714286  \n",
       "4                0.107713     58.091206                         2.035714  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Du5kGt5CWJ4J"
   },
   "source": [
    "### **Task 4. Outliers**\n",
    "\n",
    "Many of these columns have outliers. However, tree-based models are resilient to outliers, so we can ignore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxBYyXDSWPkw"
   },
   "source": [
    "### **Task 5. Variable encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57psLWIeaTk2"
   },
   "source": [
    "#### **Dummying features**\n",
    "\n",
    "In order to use `device` as an X variable, you will need to convert it to binary, where \n",
    "* `Android` -> `0`\n",
    "* `iPhone` -> `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fntUcR4-aUfH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device\n",
       "1    9213\n",
       "0    5068\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['device'] = np.where(df['device'] == 'Android', 0, 1)\n",
    "df['device'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgbEm7cOb6t8"
   },
   "source": [
    "#### **Target encoding**\n",
    "Assign a `0` for all `retained` users.\n",
    "Assign a `1` for all `churned` users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0jiVjplLb8W-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    11748\n",
       "1     2533\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create binary `target` column\n",
    "df['target'] = np.where(df['label'] == 'churned', 1, 0)\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 6: Determine the Target Variable & Evaluation Metric**\n",
    "\n",
    "Approximately 18% of the users in this dataset churned. This is an unbalanced dataset, but not extremely so. It can be modeled without any class rebalancing.\n",
    "\n",
    "Now, consider which evaluation metric is best. Remember, accuracy might not be the best gauge of performance because a model can have high accuracy on an imbalanced dataset and still fail to predict the minority class.\n",
    "\n",
    "It was already determined that the risks involved in making a false positive prediction are minimal. No one stands to get hurt, lose money, or suffer any other significant consequence if they are predicted to churn. Therefore, select the model based on the recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fD_zG59eaV2c"
   },
   "source": [
    "### **Task 7. Feature selection**\n",
    "\n",
    "Tree-based models can handle multicollinearity, so don't have to account for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5jzGjOS8iiv"
   },
   "source": [
    "### **Task 8. Modeling workflow and model selection process**\n",
    "\n",
    "The final modeling dataset contains 14,281 samples. Might be a bit little but still doable.\n",
    "\n",
    "1. Split the data into train/validation/test sets (60/20/20)\n",
    "\n",
    "Note that, when deciding the split ratio and whether or not to use a validation set to select a champion model, consider both how many samples will be in each data partition, and how many examples of the minority class each would therefore contain. In this case, a 60/20/20 split would result in \\~2,860 samples in the validation and test set, of which \\~18%&mdash;or 515 samples&mdash;would represent users who churn.\n",
    "\n",
    "2. Fit models and tune hyperparameters on the training set\n",
    "3. Perform final model selection on the validation set\n",
    "4. Assess the champion model's performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx41bVxX89Fe"
   },
   "source": [
    "### **Task 9. Split the data**\n",
    "\n",
    "Now you're ready to model. The only remaining step is to split the data into features/target variable and training/validation/test sets.\n",
    "\n",
    "1. Define a variable `X` that isolates the features.\n",
    "2. Define a variable `y` that isolates the target variable (`label2`).\n",
    "3. Split the data 80/20 into an interim training set and a test set. \n",
    "4. Split the interim training set 75/25 into a training set and a validation set, yielding a final ratio of 60/20/20 for training/validation/test sets. Remember to stratify the splits and set the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qLbapbSWDUL-"
   },
   "outputs": [],
   "source": [
    "# 1. Isolate X variables\n",
    "X = df.drop(columns=['ID', 'label', 'target'])\n",
    "\n",
    "# 2. Isolate y variable\n",
    "y = df['target']\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, stratify=y,\n",
    "                                              test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Split into train and validate sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, stratify=y_tr,\n",
    "                                                  test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moLls6Lech47"
   },
   "source": [
    "Verify the number of samples in the partitioned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qWIog8v_ckIg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8568\n",
      "2856\n",
      "2857\n"
     ]
    }
   ],
   "source": [
    "for x in [X_train, X_val, X_test]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vSaa0-xcu4Q"
   },
   "source": [
    "### **Task 10. Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vynZs5het1b_"
   },
   "source": [
    "#### **Random forest**\n",
    "\n",
    "Begin with using `GridSearchCV` to tune a random forest model.\n",
    "\n",
    "Use a dictionary `cv_params` of any of the following hyperparameters and their corresponding values to tune. The more you tune, the better your model will fit the data, but the longer it will take.\n",
    " - `n_estimators`\n",
    " - `max_depth`\n",
    " - `min_samples_split`\n",
    " - `min_samples_leaf`\n",
    " - `max_features`\n",
    "\n",
    "Instantiate the `GridSearchCV` object `rf_cv`. Pass to it as arguments:\n",
    " - estimator=`rf`\n",
    " - param_grid=`cv_params`\n",
    " - scoring=`scoring`\n",
    " - cv: define the number of cross-validation folds you want (`cv=_`)\n",
    " - refit: indicate which evaluation metric you want to use to select the model (`refit=_`) *recall in this case*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvpX9RDFc2MD"
   },
   "source": [
    "**Note:** If your model fitting takes too long, try reducing the number of options to search over in the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vj5rJWOv5O3d"
   },
   "outputs": [],
   "source": [
    "# 1. Instantiate the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune\n",
    "cv_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [6, 8, 10, 12],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# 3. Define a dictionary of scoring metrics to capture\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc_score' : 'roc_auc'\n",
    "}\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "rf_cv = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=cv_params,\n",
    "    scoring=scoring,\n",
    "    refit='recall',\n",
    "    cv = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv_WvRA1RqTl"
   },
   "source": [
    "Now fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "OXuBiTGi5ZHn"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the grid search\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m rf_cv\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      7\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining time:\u001b[39m\u001b[38;5;124m\"\u001b[39m, end \u001b[38;5;241m-\u001b[39m start, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    493\u001b[0m )(\n\u001b[0;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    495\u001b[0m         t,\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    497\u001b[0m         X,\n\u001b[0;32m    498\u001b[0m         y,\n\u001b[0;32m    499\u001b[0m         sample_weight,\n\u001b[0;32m    500\u001b[0m         i,\n\u001b[0;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    506\u001b[0m     )\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    193\u001b[0m         X,\n\u001b[0;32m    194\u001b[0m         y,\n\u001b[0;32m    195\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[0;32m    196\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\linmy\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Train the grid search\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Training time:\", end - start, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHi_YJduQOH"
   },
   "source": [
    "Examine the best average score across all the validation folds & the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YtAgrH0zy4CE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best recall score: 0.10526671396236613\n",
      "Best params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Get best recall score \n",
    "print(\"Best recall score:\", rf_cv.best_score_)\n",
    "\n",
    "# Examine best hyperparameter combo\n",
    "print(\"Best params:\", rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB-yhW9uu7dO"
   },
   "source": [
    "Asside from the accuracy, the scores aren't that good. However, recall that when you built the logistic regression model in the last course the recall was \\~0.09, which means that this model has 33% better recall and about the same accuracy, and it was trained on less data.\n",
    "\n",
    "If you want, feel free to try retuning your hyperparameters to try to get a better score. You might be able to marginally improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOlktJ6l4Tgt"
   },
   "source": [
    "#### **XGBoost**\n",
    "\n",
    " Try to improve your scores using an XGBoost model.\n",
    "\n",
    "1. Instantiate the XGBoost classifier `xgb` and set `objective='binary:logistic'`. Also set the random state.\n",
    "\n",
    "2. Create a dictionary `cv_params` of the following hyperparameters and their corresponding values to tune:\n",
    " - `max_depth`\n",
    " - `min_child_weight`\n",
    " - `learning_rate`\n",
    " - `n_estimators`\n",
    " - `col_sample`\n",
    "\n",
    "3. Define a list `scoring` of scoring metrics for grid search to capture (precision, recall, F1 score, and roc-auc).\n",
    "\n",
    "4. Instantiate the `GridSearchCV` object `xgb_cv`. Pass to it as arguments:\n",
    " - estimator=`xgb`\n",
    " - param_grid=`cv_params`\n",
    " - scoring=`scoring`\n",
    " - cv: define the number of cross-validation folds you want (`cv=_`)\n",
    " - refit: indicate which evaluation metric you want to use to select the model (`refit='recall'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ciO48nhiTqO"
   },
   "outputs": [],
   "source": [
    "# 1. Instantiate the XGBoost classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune\n",
    "cv_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [6, 8, 10, 12],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# 3. Define a list of scoring metrics to capture\n",
    "scoring = {\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc_score': 'roc_auc'}\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "xgb_cv = GridSearchCV(\n",
    "    estimator = xgb,\n",
    "    param_grid = cv_params,\n",
    "    scoring = scoring,\n",
    "    refit = 'recall',\n",
    "    cv = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y78-hQF9680x"
   },
   "source": [
    "Now fit the model to the `X_train` and `y_train` data.\n",
    "\n",
    "Note this cell might take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "dYCWs_HX6804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 108.28133988380432 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Training time:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UFLTmIDm6805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best recall score: 0.1993421052631579\n",
      "Best params: {'colsample_bytree': 0.8, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Examine best score and best hyperparameters\n",
    "print(\"Best recall score:\", xgb_cv.best_score_)\n",
    "print(\"Best params:\", xgb_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5IRnMO27KdD"
   },
   "source": [
    "This model fit the data even better than the random forest model, almost 50% better than the random forest model's recall score, while maintaining a similar accuracy and precision score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfX0SjJffkh1"
   },
   "source": [
    "### **Task 11. Model selection**\n",
    "\n",
    "Now, use the best random forest model and the best XGBoost model to predict on the validation data. Whichever performs better will be selected as the champion model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chgR3Tx8fn1s"
   },
   "source": [
    "#### **Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "DUswawM2fyAf"
   },
   "outputs": [],
   "source": [
    "# Use random forest model to predict on validation data\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uz1eb4rqf11Z"
   },
   "source": [
    "Use the `get_test_scores()` function to generate a table of scores from the predictions on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "AJ9mCl0Uf4P4"
   },
   "outputs": [],
   "source": [
    "def get_test_scores(model_name:str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores.\n",
    "\n",
    "    In:\n",
    "        model_name (string): Your choice: how the model will be named in the output table\n",
    "        preds: numpy array of test predictions\n",
    "        y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "        table: a pandas df of precision, recall, f1, and accuracy scores for your model\n",
    "    '''\n",
    "    accuracy = accuracy_score(y_test_data, preds)\n",
    "    precision = precision_score(y_test_data, preds)\n",
    "    recall = recall_score(y_test_data, preds)\n",
    "    f1 = f1_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                          'precision': [precision],\n",
    "                          'recall': [recall],\n",
    "                          'F1': [f1],\n",
    "                          'accuracy': [accuracy]\n",
    "                          })\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "22ANR4ZHf5NK"
   },
   "outputs": [],
   "source": [
    "# Get validation scores for RF model\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Append to the results table\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDeuk16igBD0"
   },
   "source": [
    "Notice that the scores went down from the training scores across all metrics, but only by very little. This means that the model did not overfit the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8h2s5RpgEER"
   },
   "source": [
    "#### **XGBoost**\n",
    "\n",
    "Now, do the same thing to get the performance scores of the XGBoost model on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mQoTuRkngHjp"
   },
   "outputs": [],
   "source": [
    "# Use XGBoost model to predict on validation data\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Get validation scores for XGBoost model\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Append to the results table\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GspkQqUNgIm3"
   },
   "source": [
    "Just like with the random forest model, the XGBoost model's validation scores were lower, but only very slightly. It is still the clear champion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HGsWfEOeWPm"
   },
   "source": [
    "<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Execute**\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Execute stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOm4n_1OgUND"
   },
   "source": [
    "### **Task 12. Use champion model to predict on test data**\n",
    "\n",
    "Now, use the champion model to predict on the test dataset. This is to give a final indication of how you should expect the model to perform on new future data, should you decide to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7BkheTIsgU2b"
   },
   "outputs": [],
   "source": [
    "# Use XGBoost model to predict on test data\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Get test scores for XGBoost model\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Append to the results table\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8L_LyIbgV1I"
   },
   "source": [
    "The recall was exactly the same as it was on the validation data, but the precision declined notably, which caused all of the other scores to drop slightly. Nonetheless, this is stil within the acceptable range for performance discrepancy between validation and test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5GNoz_QgWug"
   },
   "source": [
    "### **Task 13. Confusion matrix**\n",
    "\n",
    "Plot a confusion matrix of the champion model's predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WF3KErX8gXPc"
   },
   "outputs": [],
   "source": [
    "# Generate array of values for confusion matrix\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Plot confusion matrix\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xL4OujkgYC3"
   },
   "source": [
    "The model predicted three times as many false negatives than it did false positives, and it correctly identified only 16.6% of the users who actually churned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P33INGPmgY1o"
   },
   "source": [
    "### **Task 14. Feature importance**\n",
    "\n",
    "Use the `plot_importance` function to inspect the most important features of your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "N4fc2i8XgZoE"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU3GIZNrga5z"
   },
   "source": [
    "The XGBoost model made more use of many of the features than did the logistic regression model from the previous course, which weighted a single feature (`activity_days`) very heavily in its final prediction.\n",
    "\n",
    "If anything, this underscores the importance of feature engineering. Notice that engineered features accounted for six of the top 10 features (and three of the top five). Feature engineering is often one of the best and easiest ways to boost model performance.\n",
    "\n",
    "Also, note that the important features in one model might not be the same as the important features in another model. That's why you shouldn't discount features as unimportant without thoroughly examining them and understanding their relationship with the dependent variable, if possible. These discrepancies between features selected by models are typically caused by complex feature interactions.\n",
    "\n",
    "Remember, sometimes your data simply will not be predictive of your chosen target. This is common. Machine learning is a powerful tool, but it is not magic. If your data does not contain predictive signal, even the most complex algorithm will not be able to deliver consistent and accurate predictions. Do not be afraid to draw this conclusion.\n",
    "\n",
    "Even if you cannot use the model to make strong predictions, was the work done in vain? What insights can you report back to stakeholders?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ill21hQ4ej9-"
   },
   "source": [
    "### **Task 15. Conclusion**\n",
    "\n",
    "Now that you've built and tested your machine learning models, the next step is to share your findings with the Waze leadership team. Consider the following questions as you prepare to write your executive summary. Think about key points you may want to share with the team, and what information is most relevant to the user churn project.\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. Would you recommend using this model for churn prediction? Why or why not?\n",
    "\n",
    "2. What tradeoff was made by splitting the data into training, validation, and test sets as opposed to just training and test sets?\n",
    "\n",
    "3. What is the benefit of using a logistic regression model over an ensemble of tree-based models (like random forest or XGBoost) for classification tasks?\n",
    "\n",
    "4. What is the benefit of using an ensemble of tree-based models like random forest or XGBoost over a logistic regression model for classification tasks?\n",
    "\n",
    "5. What could you do to improve this model?\n",
    "\n",
    "6. What additional features would you like to have to help improve the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NrXTUydBady"
   },
   "source": [
    "==> ENTER YOUR RESPONSES TO QUESTIONS 1-6 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1DHsmIEwaXUmfVT4tFzyOwyyfXAX0v6IF",
     "timestamp": 1675262571681
    },
    {
     "file_id": "1oNheYh5WbljxkvoK_BMkQTey2DWnFXMs",
     "timestamp": 1674856595373
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
